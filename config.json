{
  "models": [
    {
      "name": "gpt-3.5-turbo",
      "context_length": 16385,
      "encoding": "tiktoken"
    },
    {
      "name": "gpt-4",
      "context_length": 8192,
      "encoding": "tiktoken"
    },
    {
      "name": "gpt-4-turbo",
      "context_length": 128000,
      "encoding": "tiktoken"
    },
    {
      "name": "claude-3-opus",
      "context_length": 200000,
      "encoding": "claude"
    },
    {
      "name": "claude-3-sonnet",
      "context_length": 180000,
      "encoding": "claude"
    },
    {
      "name": "claude-3-haiku",
      "context_length": 180000,
      "encoding": "claude"
    },
    {
      "name": "llama-2-7b",
      "context_length": 4096,
      "encoding": "llama"
    },
    {
      "name": "llama-2-13b",
      "context_length": 4096,
      "encoding": "llama"
    },
    {
      "name": "llama-2-70b",
      "context_length": 4096,
      "encoding": "llama"
    },
    {
      "name": "mistral-7b",
      "context_length": 8192,
      "encoding": "mistral"
    },
    {
      "name": "bert-base",
      "context_length": 512,
      "encoding": "bert"
    },
    {
      "name": "llama-3-8b",
      "context_length": 8000,
      "encoding": "llama"
    },
    {
      "name": "llama-3-70b",
      "context_length": 8000,
      "encoding": "llama"
    },
    {
      "name": "llama-3.1-405b",
      "context_length": 128000,
      "encoding": "llama"
    },
    {
      "name": "llama-4-scout",
      "context_length": 10000000,
      "encoding": "llama"
    },
    {
      "name": "llama-4-maverick",
      "context_length": 10000000,
      "encoding": "llama"
    },
    {
      "name": "claude-3.7-sonnet",
      "context_length": 200000,
      "encoding": "claude"
    },
    {
      "name": "gpt-4.5-preview",
      "context_length": 128000,
      "encoding": "tiktoken"
    },
    {
      "name": "o3-mini",
      "context_length": 200000,
      "encoding": "openai"
    }
  ]
}
